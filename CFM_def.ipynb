{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoZanella/Neural-networks---Plant-species-classification/blob/main/CFM_def.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGVIKHEz7Bon"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUf9vKFT7O1d"
      },
      "outputs": [],
      "source": [
        "%cd /gdrive/My Drive/CHALLENGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UkfYzUewc5Y"
      },
      "outputs": [],
      "source": [
        "!pip install keras_tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It40SSp_7aA2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import keras_tuner\n",
        "hp = keras_tuner.HyperParameters()\n",
        "hp1 = keras_tuner\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0woRWW4i7fR8"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJwgxLyG7g5I"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "tf.get_logger().setLevel('INFO')\n",
        "tf.autograph.set_verbosity(0)\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYR0g_Fw7ifB"
      },
      "outputs": [],
      "source": [
        "!unzip training_dataset_homework1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "2pzgaRrMNqzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdweif5H1AZZ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "IMG_SIZE = 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvSd6wrqxoBV"
      },
      "outputs": [],
      "source": [
        "class_names = [\n",
        "    \"Species1\",\n",
        "    \"Species2\",\n",
        "    \"Species3\",\n",
        "    \"Species4\",\n",
        "    \"Species5\",\n",
        "    \"Species6\",\n",
        "    \"Species7\",\n",
        "    \"Species8\"\n",
        "]\n",
        "# using\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"training_data_final\",\n",
        "    labels = \"inferred\", # means that labels are retrieved automaticallly with files name\n",
        "    label_mode = \"categorical\",\n",
        "    color_mode = \"rgb\",\n",
        "    batch_size = BATCH_SIZE,\n",
        "    image_size = (96,96),\n",
        "    seed = seed,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    shuffle = True,\n",
        "    class_names = class_names\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"training_data_final\",\n",
        "    labels = \"inferred\",\n",
        "    label_mode = \"categorical\",\n",
        "    color_mode = \"rgb\",\n",
        "    batch_size = BATCH_SIZE,\n",
        "    image_size = (96,96),\n",
        "    seed = seed,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    class_names = class_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN6jWhgQAw3e"
      },
      "source": [
        "RESCALING AND DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0on5mpWBtRQ"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7IUroBT01KZ"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [tfkl.RandomFlip(\"horizontal\"), tfkl.RandomRotation(0.1), tfkl.RandomContrast(0.5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd4SH3f3lsgl"
      },
      "source": [
        "# Base Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wESWWepo-h-w"
      },
      "outputs": [],
      "source": [
        "input_shape = (96, 96, 3)\n",
        "dropout_rate = 0.3\n",
        "epochs = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIRaZ7uXBiEf"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape,dropout_rate):\n",
        "    data_augmentation,\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "    x = tfkl.Rescaling(1./255)(input_layer)\n",
        "    x = tfkl.Normalization()(x)\n",
        "\n",
        "    x = tfkl.Conv2D(\n",
        "        filters = 64,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'conv1')(x)\n",
        "\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "\n",
        "    x = tfkl.Conv2D(\n",
        "        filters = 128,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'conv2')(x)\n",
        "\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "\n",
        "    x = tfkl.Conv2D(\n",
        "        filters = 256,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'Conv3')(x)\n",
        "\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "    x = tfkl.Dropout(dropout_rate, seed=seed, name='gap_dropout')(x)\n",
        "    x = tfkl.Dense(\n",
        "        units = 256,\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'classifier')(x)\n",
        "\n",
        "    x = tfkl.Dropout(dropout_rate, seed=seed, name='classifier_dropout')(x)\n",
        "    x = tfkl.Dense(\n",
        "        units = 256,\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'classifier1')(x)\n",
        "    x = tfkl.Dropout(dropout_rate, seed=seed, name='classifier_dropout1')(x)\n",
        "    output_layer = tfkl.Dense(\n",
        "        units = 8,\n",
        "        activation = 'softmax',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'output_layer')(x)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf9d8v34CB_A"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "normal_model = build_model(input_shape,dropout_rate,l1_lambda)\n",
        "normal_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3J1zJ5yCJqp"
      },
      "outputs": [],
      "source": [
        "history = normal_model.fit(\n",
        "    x = train_ds,\n",
        "    epochs = epochs,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)],\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJSmMDwIca90"
      },
      "outputs": [],
      "source": [
        "normal_model.save(\"normal_model_080_normalization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPuN2ojCcp5o"
      },
      "source": [
        "# XCEPTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFER LEARNING"
      ],
      "metadata": {
        "id": "asVOUn7EN5xW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGUDAYPjCSxA"
      },
      "outputs": [],
      "source": [
        "base_model = tfk.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(96,96,3)\n",
        ")\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB_3eReUGrxr"
      },
      "outputs": [],
      "source": [
        "# Use the supernet as feature extractor\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "# Apply random data augmentation to the model\n",
        "x = data_augmentation(inputs)\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.)\n",
        "scale_layer = keras.layers.Rescaling(scale = 1. /127.5, offset=-1)\n",
        "x = scale_layer(x)\n",
        "\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = tfkl.Dropout(dropout_rate, seed=seed, name='gap_dropout')(x)\n",
        "x = tfkl.Dense(\n",
        "        units = 256,\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'classifier')(x)\n",
        "\n",
        "x = tfkl.Dropout(dropout_rate, seed=seed, name='classifier_dropout')(x)\n",
        "x = tfkl.Dense(\n",
        "        units = 256,\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'classifier1')(x)\n",
        "x = tfkl.Dropout(dropout_rate, seed=seed, name='classifier_dropout1')(x)\n",
        "output_layer = tfkl.Dense(\n",
        "        units = 8,\n",
        "        activation = 'softmax',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name = 'output_layer')(x)\n",
        "\n",
        "model_tl = tfk.Model(inputs = inputs, outputs = output_layer, name = 'tl_model')\n",
        "\n",
        "model_tl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4RkDVnsZ3ve"
      },
      "outputs": [],
      "source": [
        "model_tl.compile(\n",
        "   loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D4Ow4TIIFxG"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "tl_history = model_tl.fit(\n",
        "    x = train_ds,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = 500,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwMHF_ijKAR6"
      },
      "outputs": [],
      "source": [
        "model_tl.save('TransferLearningModelXception')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMNyAdHYai8J"
      },
      "source": [
        "## FINE TUNE ALL THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrwimMkiKHwh"
      },
      "outputs": [],
      "source": [
        "# Re-load the model after transfer learning\n",
        "ft_model = tfk.models.load_model('TransferLearningModelXception')\n",
        "ft_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh8xX9zTKLTt"
      },
      "outputs": [],
      "source": [
        "# Set all layers to True\n",
        "ft_model.trainable = True\n",
        "for i, layer in enumerate(ft_model.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViIH7liXKR-d"
      },
      "outputs": [],
      "source": [
        "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting from the weights from the transfer learning phase, retrain all the layers including the ones in the feature extraction part with a very low learning rate."
      ],
      "metadata": {
        "id": "N5nxBjaUHfTY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsr3Xo0_KVzy"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "ft_history = ft_model.fit(\n",
        "    x = train_ds,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = 500,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbVkgsLiKlMI"
      },
      "outputs": [],
      "source": [
        "ft_model.save('FineTuningModelAllUnfreezed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzS7eJ9irUbq"
      },
      "source": [
        "## FINE TUNING SOME UNFREEZED"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain the model freezing the first 95 layers and retraining only the dense part."
      ],
      "metadata": {
        "id": "-XBea8ikJUjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DuIbMKcrbJD"
      },
      "outputs": [],
      "source": [
        "# Re-load the model after transfer learning\n",
        "ft_model_unfreezed = tfk.models.load_model('TransferLearningModelXception')\n",
        "ft_model_unfreezed.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg-iIklwsWxM"
      },
      "outputs": [],
      "source": [
        "# Set all VGG layers to True\n",
        "ft_model_unfreezed.get_layer('xception').trainable = True\n",
        "for i, layer in enumerate(ft_model_unfreezed.get_layer('xception').layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZz5fYm6sw2o"
      },
      "outputs": [],
      "source": [
        "# Freeze first N layers, e.g., until 14th\n",
        "for i, layer in enumerate(ft_model_unfreezed.get_layer('xception').layers[:95]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_model_unfreezed.get_layer('xception').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_model_unfreezed.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ToGC0GytA1H"
      },
      "outputs": [],
      "source": [
        "ft_model_unfreezed.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DWquaW9tGH_"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "ft_unfreezed_history = ft_model_unfreezed.fit(\n",
        "    x = train_ds,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = 500,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdYIN-OItXuD"
      },
      "outputs": [],
      "source": [
        "ft_model_unfreezed.save('FineTuningModelSomeUnfreezed')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GOGfFERJOHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESNET\n"
      ],
      "metadata": {
        "id": "pnsCwwKWOajr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFER LEARNING"
      ],
      "metadata": {
        "id": "pta-Cv4kOeG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load ResNet50 model\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=5,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False"
      ],
      "metadata": {
        "id": "F0an7p7vOoIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  tf.keras.applications.resnet50.preprocess_input\n",
        "  model = keras.Sequential()\n",
        "  model.add(data_augmentation)\n",
        "  model.add(tfkl.Resizing(180, 180, interpolation=\"bicubic\"))\n",
        "  model.add(pretrained_model)\n",
        "  model.add(tfkl.Flatten())\n",
        "  model.add(tfkl.Dense(\n",
        "      units=256,\n",
        "      activation='relu'))\n",
        "  model.add(tfkl.BatchNormalization())\n",
        "  model.add(tfkl.Dropout(rate=0.3, seed=seed))\n",
        "  model.add(tfkl.Dense(8, activation='softmax'))\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "cjZYEDVIOtIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "sVqocIo8OuDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 96, 96, 3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RmoiPGkjOuED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain the model\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    x = train_ds,\n",
        "    epochs = epochs,\n",
        "    validation_data =val_ds,\n",
        "    callbacks = [early_stopping],\n",
        "\n",
        ").history"
      ],
      "metadata": {
        "id": "EAKMktpiOuEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"TL_finale\")"
      ],
      "metadata": {
        "id": "Pf4BC8NbO2zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINE TUNING"
      ],
      "metadata": {
        "id": "ktywNLvUO6DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load the model after transfer learning\n",
        "Resnet_ft_model = tfk.models.load_model('TL_finale')\n",
        "Resnet_ft_model.summary()"
      ],
      "metadata": {
        "id": "nZMCgW5vO_3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set all Resnet layers to True\n",
        "Resnet_ft_model.get_layer('resnet50').trainable = True\n",
        "for i, layer in enumerate(Resnet_ft_model.get_layer('resnet50').layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "d_JCc4rzPApx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze first N layers, e.g., until 14th\n",
        "for i, layer in enumerate(Resnet_ft_model.get_layer('resnet50').layers[:142]):\n",
        "  layer.trainable=False\n",
        "\n",
        "for i, layer in enumerate(Resnet_ft_model.get_layer('resnet50').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "Resnet_ft_model.summary()"
      ],
      "metadata": {
        "id": "FHYKMMHjPFgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "Resnet_ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"
      ],
      "metadata": {
        "id": "POChJr1QPIYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "Resnet_ft_history = Resnet_ft_model.fit(\n",
        "    x = train_ds,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
        ").history"
      ],
      "metadata": {
        "id": "p-S_ezsCPKZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Resnet_ft_model.save(\"FT_finale\")\n",
        "del Resnet_ft_model"
      ],
      "metadata": {
        "id": "ku3sQW8gPMc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK2zrx3pu-o1"
      },
      "source": [
        "# KERAS TUNER"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the tuner with different models, we have find the sub-optimal hyperparameters both for the straightforward model,for the xception model and for the resnet model."
      ],
      "metadata": {
        "id": "7BntzFBVI4d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h25TONznvD95"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  model_kt = keras.Sequential()\n",
        "  # data augmentation\n",
        "  model_kt.add(tfkl.RandomFlip(\"horizontal\") )\n",
        "  model_kt.add(tfkl.RandomRotation(0.3))\n",
        "  model_kt.add(tfkl.RandomContrast(0.5))\n",
        "\n",
        "  model_kt.add(tfkl.Input(shape=(96,96,3), name='input_layer'))\n",
        "  model_kt.add(tfkl.Rescaling(1./255))\n",
        "\n",
        "  #convolutional part\n",
        "  model_kt.add(tfkl.Conv2D(\n",
        "        filters = 64,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'conv1'))\n",
        "  model_kt.add(tfkl.MaxPooling2D(name='mp1'))\n",
        "\n",
        "  model_kt.add(tfkl.Conv2D(\n",
        "        filters = 128,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'conv2'))\n",
        "  model_kt.add(tfkl.MaxPooling2D(name='mp2'))\n",
        "\n",
        "  model_kt.add(tfkl.Conv2D(\n",
        "        filters = 256,\n",
        "        kernel_size = 3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "        name = 'Conv3'))\n",
        "  model_kt.add(tfkl.GlobalAveragePooling2D(name='gap'))\n",
        "  #model_kt.add(tfkl.Flatten())\n",
        "\n",
        "  # dense part\n",
        "  for i in range(hp.Int(\"num_layers\", 2, 4)):\n",
        "      model_kt.add(\n",
        "          tfkl.Dense(\n",
        "              # Tune number of units separately.\n",
        "              units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "              activation=\"relu\",\n",
        "          )\n",
        "      )\n",
        "      model_kt.add(tfkl.Dropout(rate=hp.Float(\"drop\",min_value = 0.20,max_value = 0.50, step = 0.1)))\n",
        "\n",
        "  model_kt.add(tfkl.Dense(\n",
        "      units = 8,\n",
        "      activation = 'softmax',\n",
        "      kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "      name = 'output_layer'))\n",
        "  model_kt.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "  return model_kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xnMgq8859du"
      },
      "outputs": [],
      "source": [
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krucWgDg6G30"
      },
      "outputs": [],
      "source": [
        "tuner = hp1.Hyperband(\n",
        "   hypermodel = build_model,\n",
        "   objective = \"val_accuracy\",\n",
        "   max_epochs = 200,\n",
        "   hyperband_iterations = 3,\n",
        "   seed = seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb6ExOX58vXp"
      },
      "outputs": [],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "75P6Mno581bK"
      },
      "outputs": [],
      "source": [
        "tuner.search(train_ds, epochs=10, validation_data=val_ds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aPuN2ojCcp5o",
        "MK2zrx3pu-o1"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}